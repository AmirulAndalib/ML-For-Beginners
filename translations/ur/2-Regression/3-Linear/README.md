<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2f88fbc741d792890ff2f1430fe0dae0",
  "translation_date": "2025-08-29T12:53:27+00:00",
  "source_file": "2-Regression/3-Linear/README.md",
  "language_code": "ur"
}
-->
# سکائٹ لرن کا استعمال کرتے ہوئے ریگریشن ماڈل بنائیں: چار مختلف طریقے

![لکیری بمقابلہ پولینومیئل ریگریشن انفوگرافک](../../../../translated_images/linear-polynomial.5523c7cb6576ccab0fecbd0e3505986eb2d191d9378e785f82befcf3a578a6e7.ur.png)
> انفوگرافک از [دسانی مادیپالی](https://twitter.com/dasani_decoded)
## [لیکچر سے پہلے کا کوئز](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/13/)

> ### [یہ سبق R میں بھی دستیاب ہے!](../../../../2-Regression/3-Linear/solution/R/lesson_3.html)
### تعارف

اب تک آپ نے ریگریشن کے بارے میں جانا ہے اور کدو کی قیمتوں کے ڈیٹا سیٹ کے نمونے کے ساتھ کام کیا ہے، جو ہم اس سبق میں استعمال کریں گے۔ آپ نے اسے Matplotlib کا استعمال کرتے ہوئے بصری طور پر بھی دیکھا ہے۔

اب آپ مشین لرننگ کے لیے ریگریشن کو مزید گہرائی سے سمجھنے کے لیے تیار ہیں۔ اگرچہ بصری تجزیہ ڈیٹا کو سمجھنے میں مدد دیتا ہے، مشین لرننگ کی اصل طاقت _ماڈلز کی تربیت_ میں ہے۔ ماڈلز تاریخی ڈیٹا پر تربیت یافتہ ہوتے ہیں تاکہ ڈیٹا کی وابستگیوں کو خودکار طور پر سمجھ سکیں، اور یہ نئے ڈیٹا کے لیے نتائج کی پیش گوئی کرنے کی اجازت دیتے ہیں، جو ماڈل نے پہلے نہیں دیکھا ہوتا۔

اس سبق میں، آپ ریگریشن کی دو اقسام کے بارے میں مزید جانیں گے: _بنیادی لکیری ریگریشن_ اور _پولینومیئل ریگریشن_، اور ان تکنیکوں کے پیچھے کچھ ریاضی کو بھی سمجھیں گے۔ یہ ماڈلز ہمیں مختلف ان پٹ ڈیٹا کی بنیاد پر کدو کی قیمتوں کی پیش گوئی کرنے کی اجازت دیں گے۔

[![مشین لرننگ کے لیے ابتدائی رہنما - لکیری ریگریشن کو سمجھنا](https://img.youtube.com/vi/CRxFT8oTDMg/0.jpg)](https://youtu.be/CRxFT8oTDMg "مشین لرننگ کے لیے ابتدائی رہنما - لکیری ریگریشن کو سمجھنا")

> 🎥 اوپر دی گئی تصویر پر کلک کریں تاکہ لکیری ریگریشن کا مختصر ویڈیو جائزہ دیکھ سکیں۔

> اس نصاب میں، ہم ریاضی کے بارے میں کم سے کم معلومات فرض کرتے ہیں اور اسے دوسرے شعبوں سے آنے والے طلباء کے لیے قابل رسائی بنانے کی کوشش کرتے ہیں، لہذا نوٹس، 🧮 کال آؤٹس، ڈایاگرامز، اور دیگر سیکھنے کے اوزار پر نظر رکھیں جو سمجھنے میں مدد فراہم کریں۔

### پیشگی شرط

آپ کو اب تک کدو کے ڈیٹا کی ساخت سے واقف ہونا چاہیے جس کا ہم تجزیہ کر رہے ہیں۔ آپ اسے اس سبق کی _notebook.ipynb_ فائل میں پہلے سے لوڈ اور صاف شدہ حالت میں پا سکتے ہیں۔ اس فائل میں، کدو کی قیمت فی بشل ایک نئے ڈیٹا فریم میں دکھائی گئی ہے۔ یقینی بنائیں کہ آپ ان نوٹ بکس کو Visual Studio Code کے کرنلز میں چلا سکتے ہیں۔

### تیاری

یاد دہانی کے طور پر، آپ یہ ڈیٹا اس لیے لوڈ کر رہے ہیں تاکہ اس سے سوالات پوچھ سکیں۔

- کدو خریدنے کا بہترین وقت کب ہے؟
- چھوٹے کدو کے ایک کیس کی قیمت کیا ہو سکتی ہے؟
- کیا مجھے انہیں آدھے بشل کی ٹوکریوں میں خریدنا چاہیے یا 1 1/9 بشل کے ڈبے میں؟
آئیے اس ڈیٹا میں مزید گہرائی میں جائیں۔

پچھلے سبق میں، آپ نے ایک Pandas ڈیٹا فریم بنایا اور اسے اصل ڈیٹا سیٹ کے ایک حصے سے بھرا، قیمتوں کو بشل کے حساب سے معیاری بنایا۔ تاہم، ایسا کرنے سے، آپ صرف تقریباً 400 ڈیٹا پوائنٹس اور صرف خزاں کے مہینوں کے لیے ڈیٹا اکٹھا کر سکے۔

اس سبق کے ساتھ دی گئی نوٹ بک میں پہلے سے لوڈ شدہ ڈیٹا پر ایک نظر ڈالیں۔ ڈیٹا پہلے سے لوڈ شدہ ہے اور ایک ابتدائی اسکیٹر پلاٹ مہینے کے ڈیٹا کو دکھانے کے لیے بنایا گیا ہے۔ شاید ہم ڈیٹا کو مزید صاف کر کے اس کی نوعیت کے بارے میں مزید تفصیل حاصل کر سکیں۔

## ایک لکیری ریگریشن لائن

جیسا کہ آپ نے سبق 1 میں سیکھا، لکیری ریگریشن کی مشق کا مقصد ایک لائن کو پلاٹ کرنا ہے تاکہ:

- **متغیرات کے تعلقات دکھائے جا سکیں**۔ متغیرات کے درمیان تعلق کو ظاہر کریں۔
- **پیش گوئیاں کریں**۔ یہ پیش گوئی کریں کہ ایک نیا ڈیٹا پوائنٹ اس لائن کے تعلق میں کہاں گرے گا۔

یہ عام طور پر **لیسٹ اسکوائرز ریگریشن** کے لیے اس قسم کی لائن کھینچنے کے لیے استعمال ہوتا ہے۔ 'لیسٹ اسکوائرز' کا مطلب ہے کہ ریگریشن لائن کے ارد گرد کے تمام ڈیٹا پوائنٹس کو مربع کیا جاتا ہے اور پھر ان کا مجموعہ لیا جاتا ہے۔ مثالی طور پر، یہ حتمی مجموعہ جتنا ممکن ہو کم ہونا چاہیے، کیونکہ ہم غلطیوں کی کم تعداد، یا `لیسٹ اسکوائرز` چاہتے ہیں۔

ہم ایسا اس لیے کرتے ہیں کیونکہ ہم ایک ایسی لائن ماڈل کرنا چاہتے ہیں جس کا تمام ڈیٹا پوائنٹس سے کم سے کم مجموعی فاصلہ ہو۔ ہم ان شرائط کو شامل کرنے سے پہلے مربع بھی کرتے ہیں کیونکہ ہمیں اس کی سمت کے بجائے اس کی شدت کی فکر ہوتی ہے۔

> **🧮 مجھے ریاضی دکھائیں**
>
> اس لائن، جسے _بہترین فٹ کی لائن_ کہا جاتا ہے، کو [ایک مساوات](https://en.wikipedia.org/wiki/Simple_linear_regression) کے ذریعے ظاہر کیا جا سکتا ہے:
>
> ```
> Y = a + bX
> ```
>
> `X` 'وضاحتی متغیر' ہے۔ `Y` 'انحصاری متغیر' ہے۔ لائن کی ڈھلوان `b` ہے اور `a` y-انٹرسیپٹ ہے، جو اس وقت `Y` کی قیمت کو ظاہر کرتا ہے جب `X = 0` ہو۔
>
>![ڈھلوان کا حساب لگائیں](../../../../translated_images/slope.f3c9d5910ddbfcf9096eb5564254ba22c9a32d7acd7694cab905d29ad8261db3.ur.png)
>
> پہلے، ڈھلوان `b` کا حساب لگائیں۔ انفوگرافک از [جن لوپر](https://twitter.com/jenlooper)
>
> دوسرے الفاظ میں، اور ہمارے کدو کے ڈیٹا کے اصل سوال کا حوالہ دیتے ہوئے: "مہینے کے لحاظ سے فی بشل کدو کی قیمت کی پیش گوئی کریں"، `X` قیمت کو ظاہر کرے گا اور `Y` فروخت کے مہینے کو۔
>
>![مساوات مکمل کریں](../../../../translated_images/calculation.a209813050a1ddb141cdc4bc56f3af31e67157ed499e16a2ecf9837542704c94.ur.png)
>
> `Y` کی قیمت کا حساب لگائیں۔ اگر آپ تقریباً $4 ادا کر رہے ہیں، تو یہ اپریل ہونا چاہیے! انفوگرافک از [جن لوپر](https://twitter.com/jenlooper)
>
> لائن کی ڈھلوان کا حساب لگانے کے لیے ریاضی کو انٹرسیپٹ پر بھی انحصار کرنا چاہیے، یا جہاں `Y` اس وقت واقع ہے جب `X = 0` ہو۔
>
> آپ ان اقدار کے حساب کے طریقے کو [Math is Fun](https://www.mathsisfun.com/data/least-squares-regression.html) ویب سائٹ پر دیکھ سکتے ہیں۔ مزید برآں، [یہ لیسٹ اسکوائرز کیلکولیٹر](https://www.mathsisfun.com/data/least-squares-calculator.html) دیکھیں تاکہ یہ دیکھ سکیں کہ نمبروں کی قدریں لائن کو کیسے متاثر کرتی ہیں۔

## تعلق

ایک اور اصطلاح جسے سمجھنا ضروری ہے وہ ہے **تعلق کا گتانک**، جو دیے گئے X اور Y متغیرات کے درمیان ہوتا ہے۔ ایک اسکیٹر پلاٹ کا استعمال کرتے ہوئے، آپ اس گتانک کو جلدی سے دیکھ سکتے ہیں۔ ایک پلاٹ جس میں ڈیٹا پوائنٹس ایک صاف لائن میں بکھرے ہوئے ہوں، ان کا تعلق زیادہ ہوتا ہے، لیکن ایک پلاٹ جس میں ڈیٹا پوائنٹس X اور Y کے درمیان ہر جگہ بکھرے ہوں، ان کا تعلق کم ہوتا ہے۔

ایک اچھا لکیری ریگریشن ماڈل وہ ہوگا جس کا تعلق کا گتانک زیادہ ہو (1 کے قریب ہو، 0 کے بجائے) اور لیسٹ اسکوائرز ریگریشن طریقہ کے ساتھ ایک ریگریشن لائن ہو۔

✅ اس سبق کے ساتھ دی گئی نوٹ بک چلائیں اور مہینے سے قیمت کے اسکیٹر پلاٹ کو دیکھیں۔ کیا کدو کی فروخت کے لیے مہینے سے قیمت کے تعلق کا ڈیٹا آپ کے بصری تجزیے کے مطابق زیادہ یا کم تعلق ظاہر کرتا ہے؟ کیا یہ اس وقت بدلتا ہے جب آپ `مہینے` کے بجائے زیادہ باریک پیمائش استعمال کرتے ہیں، جیسے *سال کا دن* (یعنی سال کے آغاز سے دنوں کی تعداد)؟

کوڈ میں، ہم فرض کریں گے کہ ہم نے ڈیٹا کو صاف کر لیا ہے اور ایک ڈیٹا فریم حاصل کیا ہے جسے `new_pumpkins` کہا جاتا ہے، جو درج ذیل کے مشابہ ہے:

ID | مہینہ | سال کا دن | قسم | شہر | پیکج | کم قیمت | زیادہ قیمت | قیمت
---|-------|-----------|---------|------|---------|-----------|------------|-------
70 | 9 | 267 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 15.0 | 15.0 | 13.636364
71 | 9 | 267 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 18.0 | 18.0 | 16.363636
72 | 10 | 274 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 18.0 | 18.0 | 16.363636
73 | 10 | 274 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 17.0 | 17.0 | 15.454545
74 | 10 | 281 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 15.0 | 15.0 | 13.636364

> ڈیٹا کو صاف کرنے کا کوڈ [`notebook.ipynb`](notebook.ipynb) میں دستیاب ہے۔ ہم نے پچھلے سبق میں کیے گئے وہی صفائی کے اقدامات کیے ہیں، اور `DayOfYear` کالم کو درج ذیل اظہار کا استعمال کرتے ہوئے شمار کیا ہے:

```python
day_of_year = pd.to_datetime(pumpkins['Date']).apply(lambda dt: (dt-datetime(dt.year,1,1)).days)
```

اب جب کہ آپ لکیری ریگریشن کے پیچھے ریاضی کو سمجھ چکے ہیں، آئیے ایک ریگریشن ماڈل بنائیں تاکہ یہ دیکھ سکیں کہ ہم کدو کے پیکجوں کی قیمتوں کی پیش گوئی کر سکتے ہیں یا نہیں۔ کوئی شخص جو چھٹی کے کدو کے باغ کے لیے کدو خرید رہا ہو، وہ یہ معلومات حاصل کرنا چاہے گا تاکہ کدو کے پیکجوں کی خریداری کو بہتر بنا سکے۔

## تعلق کی تلاش

[![مشین لرننگ کے لیے ابتدائی رہنما - تعلق کی تلاش: لکیری ریگریشن کی کلید](https://img.youtube.com/vi/uoRq-lW2eQo/0.jpg)](https://youtu.be/uoRq-lW2eQo "مشین لرننگ کے لیے ابتدائی رہنما - تعلق کی تلاش: لکیری ریگریشن کی کلید")

> 🎥 اوپر دی گئی تصویر پر کلک کریں تاکہ تعلق کا مختصر ویڈیو جائزہ دیکھ سکیں۔

پچھلے سبق سے آپ نے شاید دیکھا ہوگا کہ مختلف مہینوں کے لیے اوسط قیمت کچھ اس طرح نظر آتی ہے:

<img alt="مہینے کے لحاظ سے اوسط قیمت" src="../2-Data/images/barchart.png" width="50%"/>

یہ ظاہر کرتا ہے کہ کچھ تعلق ہونا چاہیے، اور ہم `مہینے` اور `قیمت` کے درمیان، یا `سال کے دن` اور `قیمت` کے درمیان تعلق کی پیش گوئی کرنے کے لیے لکیری ریگریشن ماڈل کی تربیت کرنے کی کوشش کر سکتے ہیں۔ یہاں اسکیٹر پلاٹ ہے جو دوسرے تعلق کو ظاہر کرتا ہے:

<img alt="قیمت بمقابلہ سال کے دن کا اسکیٹر پلاٹ" src="images/scatter-dayofyear.png" width="50%" /> 

آئیے `corr` فنکشن کا استعمال کرتے ہوئے تعلق دیکھیں:

```python
print(new_pumpkins['Month'].corr(new_pumpkins['Price']))
print(new_pumpkins['DayOfYear'].corr(new_pumpkins['Price']))
```

ایسا لگتا ہے کہ تعلق بہت کم ہے، `مہینے` کے لحاظ سے -0.15 اور `سال کے دن` کے لحاظ سے -0.17، لیکن ایک اور اہم تعلق ہو سکتا ہے۔ ایسا لگتا ہے کہ مختلف کدو کی اقسام کے مطابق قیمتوں کے مختلف کلسٹرز ہیں۔ اس مفروضے کی تصدیق کے لیے، آئیے ہر کدو کے زمرے کو مختلف رنگ کے ساتھ پلاٹ کریں۔ `scatter` پلاٹنگ فنکشن کو `ax` پیرامیٹر پاس کر کے ہم تمام پوائنٹس کو ایک ہی گراف پر پلاٹ کر سکتے ہیں:

```python
ax=None
colors = ['red','blue','green','yellow']
for i,var in enumerate(new_pumpkins['Variety'].unique()):
    df = new_pumpkins[new_pumpkins['Variety']==var]
    ax = df.plot.scatter('DayOfYear','Price',ax=ax,c=colors[i],label=var)
```

<img alt="قیمت بمقابلہ سال کے دن کا اسکیٹر پلاٹ" src="images/scatter-dayofyear-color.png" width="50%" /> 

ہماری تحقیق سے پتہ چلتا ہے کہ قسم کا مجموعی قیمت پر زیادہ اثر ہوتا ہے بجائے اس کے کہ اصل فروخت کی تاریخ۔ ہم یہ ایک بار گراف کے ساتھ دیکھ سکتے ہیں:

```python
new_pumpkins.groupby('Variety')['Price'].mean().plot(kind='bar')
```

<img alt="قسم کے لحاظ سے قیمت کا بار گراف" src="images/price-by-variety.png" width="50%" /> 

آئیے فی الحال صرف ایک کدو کی قسم، 'پائی ٹائپ' پر توجہ مرکوز کریں، اور دیکھیں کہ تاریخ کا قیمت پر کیا اثر پڑتا ہے:

```python
pie_pumpkins = new_pumpkins[new_pumpkins['Variety']=='PIE TYPE']
pie_pumpkins.plot.scatter('DayOfYear','Price') 
```
<img alt="قیمت بمقابلہ سال کے دن کا اسکیٹر پلاٹ" src="images/pie-pumpkins-scatter.png" width="50%" /> 

اگر ہم اب `corr` فنکشن کا استعمال کرتے ہوئے `قیمت` اور `سال کے دن` کے درمیان تعلق کا حساب لگائیں، تو ہمیں کچھ `-0.27` جیسا نتیجہ ملے گا - جس کا مطلب ہے کہ پیش گوئی کرنے والے ماڈل کی تربیت کرنا معنی رکھتا ہے۔

> لکیری ریگریشن ماڈل کی تربیت سے پہلے، یہ یقینی بنانا ضروری ہے کہ ہمارا ڈیٹا صاف ہے۔ لکیری ریگریشن خالی قدروں کے ساتھ اچھا کام نہیں کرتا، اس لیے یہ تمام خالی خانوں کو ختم کرنے کے لیے سمجھ میں آتا ہے:

```python
pie_pumpkins.dropna(inplace=True)
pie_pumpkins.info()
```

ایک اور طریقہ یہ ہوگا کہ ان خالی قدروں کو متعلقہ کالم کی اوسط قدروں سے پُر کیا جائے۔

## سادہ لکیری ریگریشن

[![مشین لرننگ کے لیے ابتدائی رہنما - سکائٹ لرن کا استعمال کرتے ہوئے لکیری اور پولینومیئل ریگریشن](https://img.youtube.com/vi/e4c_UP2fSjg/0.jpg)](https://youtu.be/e4c_UP2fSjg "مشین لرننگ کے لیے ابتدائی رہنما - سکائٹ لرن کا استعمال کرتے ہوئے لکیری اور پولینومیئل ریگریشن")

> 🎥 اوپر دی گئی تصویر پر کلک کریں تاکہ لکیری اور پولینومیئل ریگریشن کا مختصر ویڈیو جائزہ دیکھ سکیں۔

ہمارے لکیری ریگریشن ماڈل کی تربیت کے لیے، ہم **سکائٹ لرن** لائبریری کا استعمال کریں گے۔

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
```

ہم ان پٹ قدروں (فیچرز) اور متوقع آؤٹ پٹ (لیبل) کو الگ الگ numpy arrays میں تقسیم کر کے شروع کرتے ہیں:

```python
X = pie_pumpkins['DayOfYear'].to_numpy().reshape(-1,1)
y = pie_pumpkins['Price']
```

> نوٹ کریں کہ ہمیں ان پٹ ڈیٹا پر `reshape` انجام دینا پڑا تاکہ لکیری ریگریشن پیکج اسے صحیح طریقے سے سمجھ سکے۔ لکیری ریگریشن ایک 2D-array کو ان پٹ کے طور پر توقع کرتا ہے، جہاں array کی ہر قطار ان پٹ فیچرز کے ویکٹر سے مطابقت رکھتی ہے۔ ہمارے معاملے میں، چونکہ ہمارے پاس صرف ایک ان پٹ ہے - ہمیں N×1 شکل کے ساتھ ایک array کی ضرورت ہے، جہاں N ڈیٹا سیٹ کا سائز ہے۔

پھر، ہمیں ڈیٹا کو ٹرین اور ٹیسٹ ڈیٹا سیٹس میں تقسیم کرنے کی ضرورت ہے، تاکہ ہم تربیت کے بعد اپنے ماڈل کی توثیق کر سکیں:

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
```

آخر میں، اصل لکیری ریگریشن ماڈل کی تربیت میں صرف دو لائنز کوڈ لگتے ہیں۔ ہم `LinearRegression` آبجیکٹ کی وضاحت کرتے ہیں، اور اسے `fit` طریقہ استعمال کرتے ہوئے اپنے ڈیٹا پر فٹ کرتے ہیں:

```python
lin_reg = LinearRegression()
lin_reg.fit(X_train,y_train)
```

`LinearRegression` آبجیکٹ `fit` کرنے کے بعد ریگریشن کے تمام گتانک پر مشتمل ہوتا ہے، جن تک `.coef_` پراپرٹی کا استعمال کرتے ہوئے رسائی حاصل کی جا سکتی ہے۔ ہمارے معاملے میں، صرف ایک گتانک ہے، جو تقریباً `-0.017` کے قریب ہونا چاہیے۔ اس کا مطلب ہے کہ وقت کے ساتھ قیمتیں تھوڑی کم ہوتی دکھائی دیتی ہیں، لیکن زیادہ نہیں، تقریباً 2 سینٹ فی دن۔ ہم Y-axis کے ساتھ ریگریشن کے انٹرسیپشن پوائنٹ تک بھی `lin_reg.intercept_` کا استعمال کرتے ہوئے رسائی حاصل کر سکتے ہیں - یہ ہمارے معاملے میں تقریباً `21` ہوگا، جو سال کے آغاز میں قیمت کی نشاندہی کرتا ہے۔

یہ دیکھنے کے لیے کہ ہمارا ماڈل کتنا درست ہے، ہم ٹیسٹ ڈیٹا سیٹ پر قیمتوں کی پیش گوئی کر سکتے ہیں، اور پھر یہ ماپ سکتے ہیں کہ ہماری پیش گوئیاں متوقع قدروں کے کتنی قریب ہیں۔ یہ میٹرکس کے ذریعے کیا جا سکتا ہے جسے mean square error (MSE) کہا جاتا ہے، جو متوقع اور پیش گوئی کی گئی قدروں کے درمیان تمام مربع فرق کا اوسط ہے۔

```python
pred = lin_reg.predict(X_test)

mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')
```
ہماری غلطی تقریباً 2 پوائنٹس کے ارد گرد ہے، جو کہ ~17% ہے۔ یہ زیادہ اچھا نہیں ہے۔ ماڈل کے معیار کا ایک اور اشارہ **coefficient of determination** ہے، جسے اس طرح حاصل کیا جا سکتا ہے:

```python
score = lin_reg.score(X_train,y_train)
print('Model determination: ', score)
```  
اگر قدر 0 ہو، تو اس کا مطلب ہے کہ ماڈل ان پٹ ڈیٹا کو مدنظر نہیں رکھتا اور *بدترین لکیری پیش گوئی کنندہ* کے طور پر کام کرتا ہے، جو صرف نتیجے کی اوسط قدر ہے۔ قدر 1 کا مطلب ہے کہ ہم تمام متوقع نتائج کو مکمل طور پر پیش گوئی کر سکتے ہیں۔ ہمارے معاملے میں، coefficient تقریباً 0.06 ہے، جو کہ کافی کم ہے۔

ہم ٹیسٹ ڈیٹا کو ریگریشن لائن کے ساتھ بھی پلاٹ کر سکتے ہیں تاکہ بہتر طور پر دیکھ سکیں کہ ہمارے معاملے میں ریگریشن کیسے کام کرتا ہے:

```python
plt.scatter(X_test,y_test)
plt.plot(X_test,pred)
```  

<img alt="Linear regression" src="images/linear-results.png" width="50%" />

## پولینومیل ریگریشن  

لکیری ریگریشن کی ایک اور قسم پولینومیل ریگریشن ہے۔ کبھی کبھار متغیرات کے درمیان ایک لکیری تعلق ہوتا ہے - جیسے کدو کا حجم جتنا بڑا ہوگا، قیمت اتنی زیادہ ہوگی - لیکن کبھی کبھار ان تعلقات کو ایک سیدھی لائن یا سطح کے طور پر پلاٹ نہیں کیا جا سکتا۔

✅ یہاں [کچھ مزید مثالیں](https://online.stat.psu.edu/stat501/lesson/9/9.8) ہیں جو پولینومیل ریگریشن استعمال کر سکتی ہیں۔

تاریخ اور قیمت کے تعلق پر دوبارہ نظر ڈالیں۔ کیا یہ scatterplot ایسا لگتا ہے کہ اسے لازمی طور پر ایک سیدھی لائن کے ذریعے تجزیہ کیا جانا چاہیے؟ کیا قیمتیں اتار چڑھاؤ نہیں کر سکتیں؟ اس صورت میں، آپ پولینومیل ریگریشن آزما سکتے ہیں۔

✅ پولینومیلز ریاضیاتی اظہار ہیں جو ایک یا زیادہ متغیرات اور coefficients پر مشتمل ہو سکتے ہیں۔

پولینومیل ریگریشن ایک مڑے ہوئے لائن بناتا ہے تاکہ غیر لکیری ڈیٹا کو بہتر طور پر فٹ کیا جا سکے۔ ہمارے معاملے میں، اگر ہم ان پٹ ڈیٹا میں `DayOfYear` متغیر کو مربع کریں، تو ہم اپنے ڈیٹا کو ایک parabolic curve کے ساتھ فٹ کر سکیں گے، جس کا ایک کم از کم نقطہ سال کے اندر ہوگا۔

Scikit-learn ایک مفید [pipeline API](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html?highlight=pipeline#sklearn.pipeline.make_pipeline) شامل کرتا ہے تاکہ ڈیٹا پروسیسنگ کے مختلف مراحل کو ایک ساتھ جوڑا جا سکے۔ **پائپ لائن** **estimators** کی ایک زنجیر ہے۔ ہمارے معاملے میں، ہم ایک پائپ لائن بنائیں گے جو پہلے ہمارے ماڈل میں پولینومیل فیچرز شامل کرے گی، اور پھر ریگریشن کو تربیت دے گی:

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())

pipeline.fit(X_train,y_train)
```  

`PolynomialFeatures(2)` استعمال کرنے کا مطلب ہے کہ ہم ان پٹ ڈیٹا سے تمام دوسرے درجے کے پولینومیلز شامل کریں گے۔ ہمارے معاملے میں، یہ صرف `DayOfYear`<sup>2</sup> ہوگا، لیکن دو ان پٹ متغیرات X اور Y دیے گئے، یہ X<sup>2</sup>, XY اور Y<sup>2</sup> شامل کرے گا۔ اگر ہم چاہیں تو ہم اعلی درجے کے پولینومیلز بھی استعمال کر سکتے ہیں۔

پائپ لائنز کو اسی طرح استعمال کیا جا سکتا ہے جیسے اصل `LinearRegression` آبجیکٹ، یعنی ہم پائپ لائن کو `fit` کر سکتے ہیں، اور پھر `predict` استعمال کر کے پیش گوئی کے نتائج حاصل کر سکتے ہیں۔ یہاں گراف ہے جو ٹیسٹ ڈیٹا اور approximation curve دکھاتا ہے:

<img alt="Polynomial regression" src="images/poly-results.png" width="50%" />

پولینومیل ریگریشن استعمال کرتے ہوئے، ہم قدرے کم MSE اور زیادہ determination حاصل کر سکتے ہیں، لیکن نمایاں طور پر نہیں۔ ہمیں دیگر فیچرز کو مدنظر رکھنا ہوگا!

> آپ دیکھ سکتے ہیں کہ کدو کی کم از کم قیمتیں کہیں ہالووین کے ارد گرد دیکھی جاتی ہیں۔ آپ اس کی وضاحت کیسے کریں گے؟

🎃 مبارک ہو، آپ نے ایک ماڈل بنایا ہے جو پائی کدو کی قیمت کی پیش گوئی کرنے میں مدد کر سکتا ہے۔ آپ شاید تمام کدو کی اقسام کے لیے یہی طریقہ کار دہرا سکتے ہیں، لیکن یہ تھکا دینے والا ہوگا۔ آئیے اب سیکھتے ہیں کہ اپنے ماڈل میں کدو کی قسم کو کیسے مدنظر رکھا جائے!

## کیٹیگوریکل فیچرز  

ایک مثالی دنیا میں، ہم مختلف کدو کی اقسام کے لیے قیمتوں کی پیش گوئی کرنے کے قابل ہونا چاہتے ہیں، وہ بھی ایک ہی ماڈل استعمال کرتے ہوئے۔ تاہم، `Variety` کالم `Month` جیسے کالمز سے کچھ مختلف ہے، کیونکہ اس میں غیر عددی اقدار شامل ہیں۔ ایسے کالمز کو **categorical** کہا جاتا ہے۔

[![ML for beginners - Categorical Feature Predictions with Linear Regression](https://img.youtube.com/vi/DYGliioIAE0/0.jpg)](https://youtu.be/DYGliioIAE0 "ML for beginners - Categorical Feature Predictions with Linear Regression")

> 🎥 اوپر دی گئی تصویر پر کلک کریں تاکہ کیٹیگوریکل فیچرز کے استعمال پر ایک مختصر ویڈیو دیکھ سکیں۔

یہاں آپ دیکھ سکتے ہیں کہ اوسط قیمت قسم پر کیسے منحصر ہے:

<img alt="Average price by variety" src="images/price-by-variety.png" width="50%" />

قسم کو مدنظر رکھنے کے لیے، ہمیں پہلے اسے عددی شکل میں تبدیل کرنا ہوگا، یا **encode** کرنا ہوگا۔ ہم اسے کرنے کے کئی طریقے استعمال کر سکتے ہیں:

* سادہ **numeric encoding** مختلف اقسام کی ایک جدول بنائے گا، اور پھر قسم کے نام کو اس جدول میں ایک انڈیکس سے بدل دے گا۔ یہ لکیری ریگریشن کے لیے بہترین خیال نہیں ہے، کیونکہ لکیری ریگریشن انڈیکس کی اصل عددی قدر کو لیتا ہے، اور اسے نتیجے میں شامل کرتا ہے، کسی coefficient سے ضرب دے کر۔ ہمارے معاملے میں، انڈیکس نمبر اور قیمت کے درمیان تعلق واضح طور پر غیر لکیری ہے، چاہے ہم یہ یقینی بنائیں کہ انڈیکسز کسی مخصوص ترتیب میں ہیں۔
* **One-hot encoding** `Variety` کالم کو 4 مختلف کالمز سے بدل دے گا، ہر قسم کے لیے ایک کالم۔ ہر کالم میں `1` ہوگا اگر متعلقہ قطار دی گئی قسم کی ہو، اور `0` ورنہ۔ اس کا مطلب ہے کہ لکیری ریگریشن میں چار coefficients ہوں گے، ہر کدو کی قسم کے لیے ایک، جو اس مخصوص قسم کے لیے "ابتدائی قیمت" (یا "اضافی قیمت") کے ذمہ دار ہوں گے۔

نیچے دیا گیا کوڈ دکھاتا ہے کہ ہم قسم کو one-hot encode کیسے کر سکتے ہیں:

```python
pd.get_dummies(new_pumpkins['Variety'])
```  

 ID | FAIRYTALE | MINIATURE | MIXED HEIRLOOM VARIETIES | PIE TYPE  
----|-----------|-----------|--------------------------|----------  
70 | 0 | 0 | 0 | 1  
71 | 0 | 0 | 0 | 1  
... | ... | ... | ... | ...  
1738 | 0 | 1 | 0 | 0  
1739 | 0 | 1 | 0 | 0  
1740 | 0 | 1 | 0 | 0  
1741 | 0 | 1 | 0 | 0  
1742 | 0 | 1 | 0 | 0  

one-hot encoded قسم کو ان پٹ کے طور پر استعمال کرتے ہوئے لکیری ریگریشن کو تربیت دینے کے لیے، ہمیں صرف `X` اور `y` ڈیٹا کو صحیح طریقے سے initialize کرنے کی ضرورت ہے:

```python
X = pd.get_dummies(new_pumpkins['Variety'])
y = new_pumpkins['Price']
```  

باقی کوڈ وہی ہے جو ہم نے اوپر لکیری ریگریشن کو تربیت دینے کے لیے استعمال کیا تھا۔ اگر آپ اسے آزمائیں، تو آپ دیکھیں گے کہ mean squared error تقریباً وہی ہے، لیکن ہمیں بہت زیادہ coefficient of determination (~77%) ملتا ہے۔ مزید درست پیش گوئی حاصل کرنے کے لیے، ہم مزید کیٹیگوریکل فیچرز کو مدنظر رکھ سکتے ہیں، اور عددی فیچرز جیسے `Month` یا `DayOfYear` کو بھی۔ ایک بڑے فیچرز کے array کو حاصل کرنے کے لیے، ہم `join` استعمال کر سکتے ہیں:

```python
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']
```  

یہاں ہم `City` اور `Package` قسم کو بھی مدنظر رکھتے ہیں، جو ہمیں MSE 2.84 (10%) اور determination 0.94 دیتا ہے!

## سب کچھ ایک ساتھ رکھنا  

بہترین ماڈل بنانے کے لیے، ہم اوپر دی گئی مثال سے مشترکہ (one-hot encoded کیٹیگوریکل + عددی) ڈیٹا کو پولینومیل ریگریشن کے ساتھ استعمال کر سکتے ہیں۔ آپ کی سہولت کے لیے یہاں مکمل کوڈ دیا گیا ہے:

```python
# set up training data
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']

# make train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# setup and train the pipeline
pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())
pipeline.fit(X_train,y_train)

# predict results for test data
pred = pipeline.predict(X_test)

# calculate MSE and determination
mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')

score = pipeline.score(X_train,y_train)
print('Model determination: ', score)
```  

یہ ہمیں تقریباً 97% کا بہترین determination coefficient اور MSE=2.23 (~8% پیش گوئی کی غلطی) دے گا۔

| ماڈل | MSE | Determination |  
|-------|-----|---------------|  
| `DayOfYear` Linear | 2.77 (17.2%) | 0.07 |  
| `DayOfYear` Polynomial | 2.73 (17.0%) | 0.08 |  
| `Variety` Linear | 5.24 (19.7%) | 0.77 |  
| All features Linear | 2.84 (10.5%) | 0.94 |  
| All features Polynomial | 2.23 (8.25%) | 0.97 |  

🏆 شاباش! آپ نے ایک سبق میں چار ریگریشن ماڈلز بنائے، اور ماڈل کے معیار کو 97% تک بہتر بنایا۔ ریگریشن کے آخری حصے میں، آپ سیکھیں گے کہ زمرے کا تعین کرنے کے لیے Logistic Regression کیسے استعمال کریں۔

---
## 🚀چیلنج  

اس نوٹ بک میں مختلف متغیرات کو آزمائیں تاکہ دیکھ سکیں کہ correlation ماڈل کی درستگی سے کیسے مطابقت رکھتا ہے۔

## [لیکچر کے بعد کا کوئز](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/14/)

## جائزہ اور خود مطالعہ  

اس سبق میں ہم نے لکیری ریگریشن کے بارے میں سیکھا۔ ریگریشن کی دیگر اہم اقسام بھی ہیں۔ Stepwise, Ridge, Lasso اور Elasticnet تکنیکوں کے بارے میں پڑھیں۔ مزید سیکھنے کے لیے ایک اچھا کورس [Stanford Statistical Learning course](https://online.stanford.edu/courses/sohs-ystatslearning-statistical-learning) ہے۔

## اسائنمنٹ  

[ماڈل بنائیں](assignment.md)  

---

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا غیر درستیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔